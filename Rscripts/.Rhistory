<<<<<<< HEAD
total_deaths=c(g4_mean_td),
total_deaths_per_million=c(g4_mean_tdpm),
new_deaths=c(g4_mean_nd),
population=c(g4_mean_p),
median_age=c(g4_mean_ma),
gdp_per_capita=c(g4_mean_gdp),
cardiovascular_deaths=c(g4_mean_cd),
diabetes_deaths=c(g4_mean_dd))
# hacemos prediccion
g4_pred_new_cases <- predict(object=lm_c_g4, newdata=g4_df_pred)
# creamos df con la prediccion y fecha actual
g4_pred_df_result <- data.frame(date=g4_df_pred$date,g4_pred_new_cases)
# Leemos las predicciones anteriores...
g4_pred_df_final <- read.csv("C-top10Cluster4Pred.csv")
g4_pred_df_final$date <- as.Date(g4_pred_df_final$date, format="%Y-%m-%d")
g4_pred_df_final <- subset(g4_pred_df_final, select = -c(X))
# creamos un df con las predicciones anteriores + actual
g4_pred_df_final <- rbind(g4_pred_df_final,g4_pred_df_result)
# Export predictions for each cluster
write.csv(g4_pred_df_final, file = "C-top10Cluster4Pred.csv")
lm_c_g5 <- lm(new_cases ~ total_cases + total_cases_per_million + total_deaths +
total_deaths_per_million + total_tests_per_thousand + total_tests + new_deaths +
population + cardiovascular_deaths + pulmonary_deaths + diabetes_deaths + date, c_g5)
summary(lm_c_g5)
# Hacemos la media de las variables para tener los datos medios del cluster
# eliminamos total_tests_per_thousand y total_tests de la prediccion porque en este cluster hay demasiados NA's
g5_mean_tc <- mean(g5_pred_subset$total_cases, na.rm = TRUE)
# Cogemos los datos del cluster g5, para la fecha más actual del dataframe
# Duda: ¿Está bien coger sólo 1 día o tendríamos que haber cogido más para hacer la predicción?
g5_pred_subset <- subset(c_g5, date == max(c_g5$date))
# Hacemos la media de las variables para tener los datos medios del cluster
# eliminamos total_tests_per_thousand y total_tests de la prediccion porque en este cluster hay demasiados NA's
g5_mean_tc <- mean(g5_pred_subset$total_cases, na.rm = TRUE)
g5_mean_tcpm <- mean(g5_pred_subset$total_cases_per_million, na.rm = TRUE)
g5_mean_td <- mean(g5_pred_subset$total_deaths,na.rm = TRUE)
g5_mean_tdpm <- mean(g5_pred_subset$total_deaths_per_million, na.rm = TRUE)
g5_mean_ttpt <- mean(g5_pred_subset$total_tests_per_thousand, na.rm = TRUE)
g5_mean_tt <- mean(g5_pred_subset$total_tests, na.rm = TRUE)
g5_mean_nd <- mean(g5_pred_subset$new_deaths, na.rm = TRUE)
g5_mean_p <- mean(g5_pred_subset$population, na.rm = TRUE)
g5_mean_cd <- mean(g5_pred_subset$cardiovascular_deaths, na.rm = TRUE)
g5_mean_pd <- mean(g5_pred_subset$pulmonary_deaths, na.rm = TRUE)
g5_mean_dd <- mean(g5_pred_subset$diabetes_deaths, na.rm = TRUE)
# Hacemos la media de las variables para tener los datos medios del cluster
# eliminamos total_tests_per_thousand y total_tests de la prediccion porque en este cluster hay demasiados NA's
g5_mean_tc <- mean(g5_pred_subset$total_cases, na.rm = TRUE)
g5_mean_tcpm <- mean(g5_pred_subset$total_cases_per_million, na.rm = TRUE)
g5_mean_td <- mean(g5_pred_subset$total_deaths,na.rm = TRUE)
g5_mean_tdpm <- mean(g5_pred_subset$total_deaths_per_million, na.rm = TRUE)
#g5_mean_ttpt <- mean(g5_pred_subset$total_tests_per_thousand, na.rm = TRUE)
#g5_mean_tt <- mean(g5_pred_subset$total_tests, na.rm = TRUE)
g5_mean_nd <- mean(g5_pred_subset$new_deaths, na.rm = TRUE)
g5_mean_p <- mean(g5_pred_subset$population, na.rm = TRUE)
g5_mean_cd <- mean(g5_pred_subset$cardiovascular_deaths, na.rm = TRUE)
g5_mean_pd <- mean(g5_pred_subset$pulmonary_deaths, na.rm = TRUE)
g5_mean_dd <- mean(g5_pred_subset$diabetes_deaths, na.rm = TRUE)
today5 <- max(c_g5$date)
lm_c_g5 <- lm(new_cases ~ total_cases + total_cases_per_million + total_deaths +
total_deaths_per_million + new_deaths +
population + cardiovascular_deaths + pulmonary_deaths + diabetes_deaths + date, c_g5)
# Cogemos los datos del cluster g5, para la fecha más actual del dataframe
# Duda: ¿Está bien coger sólo 1 día o tendríamos que haber cogido más para hacer la predicción?
g5_pred_subset <- subset(c_g5, date == max(c_g5$date))
# Hacemos la media de las variables para tener los datos medios del cluster
# eliminamos total_tests_per_thousand y total_tests de la prediccion porque en este cluster hay demasiados NA's
g5_mean_tc <- mean(g5_pred_subset$total_cases, na.rm = TRUE)
g5_mean_tcpm <- mean(g5_pred_subset$total_cases_per_million, na.rm = TRUE)
g5_mean_td <- mean(g5_pred_subset$total_deaths,na.rm = TRUE)
g5_mean_tdpm <- mean(g5_pred_subset$total_deaths_per_million, na.rm = TRUE)
#g5_mean_ttpt <- mean(g5_pred_subset$total_tests_per_thousand, na.rm = TRUE)
#g5_mean_tt <- mean(g5_pred_subset$total_tests, na.rm = TRUE)
g5_mean_nd <- mean(g5_pred_subset$new_deaths, na.rm = TRUE)
g5_mean_p <- mean(g5_pred_subset$population, na.rm = TRUE)
g5_mean_cd <- mean(g5_pred_subset$cardiovascular_deaths, na.rm = TRUE)
g5_mean_pd <- mean(g5_pred_subset$pulmonary_deaths, na.rm = TRUE)
g5_mean_dd <- mean(g5_pred_subset$diabetes_deaths, na.rm = TRUE)
today5 <- max(c_g5$date)
g5_df_pred <- data.frame(date=c(today5),
total_cases=c(g5_mean_tc),
total_cases_per_million=c(g5_mean_tcpm),
total_deaths=c(g5_mean_td),
total_deaths_per_million=c(g5_mean_tdpm),
new_deaths=c(g5_mean_nd),
population=c(g5_mean_p),
median_age=c(g5_mean_ma),
gdp_per_capita=c(g5_mean_gdp),
cardiovascular_deaths=c(g5_mean_cd),
diabetes_deaths=c(g5_mean_dd))
g5_df_pred <- data.frame(date=c(today5),
total_cases=c(g5_mean_tc),
total_cases_per_million=c(g5_mean_tcpm),
total_deaths=c(g5_mean_td),
total_deaths_per_million=c(g5_mean_tdpm),
new_deaths=c(g5_mean_nd),
population=c(g5_mean_p),
pulmonary_deaths=c(g5_mean_pd),
cardiovascular_deaths=c(g5_mean_cd),
diabetes_deaths=c(g5_mean_dd))
# eliminamos las columnas que la media da NA o nan
g5_df_pred <- g5_df_pred[ , colSums(is.na(g5_df_pred)) == 0]
lm_c_g5 <- lm(new_cases ~ total_cases + total_cases_per_million + total_deaths +
total_deaths_per_million + new_deaths +
population + cardiovascular_deaths + pulmonary_deaths + diabetes_deaths + date, c_g5)
# Cogemos los datos del cluster g5, para la fecha más actual del dataframe
# Duda: ¿Está bien coger sólo 1 día o tendríamos que haber cogido más para hacer la predicción?
g5_pred_subset <- subset(c_g5, date == max(c_g5$date))
# Hacemos la media de las variables para tener los datos medios del cluster
# eliminamos total_tests_per_thousand y total_tests de la prediccion porque en este cluster hay demasiados NA's
g5_mean_tc <- mean(g5_pred_subset$total_cases, na.rm = TRUE)
g5_mean_tcpm <- mean(g5_pred_subset$total_cases_per_million, na.rm = TRUE)
g5_mean_td <- mean(g5_pred_subset$total_deaths,na.rm = TRUE)
g5_mean_tdpm <- mean(g5_pred_subset$total_deaths_per_million, na.rm = TRUE)
#g5_mean_ttpt <- mean(g5_pred_subset$total_tests_per_thousand, na.rm = TRUE)
#g5_mean_tt <- mean(g5_pred_subset$total_tests, na.rm = TRUE)
g5_mean_nd <- mean(g5_pred_subset$new_deaths, na.rm = TRUE)
g5_mean_p <- mean(g5_pred_subset$population, na.rm = TRUE)
g5_mean_cd <- mean(g5_pred_subset$cardiovascular_deaths, na.rm = TRUE)
g5_mean_pd <- mean(g5_pred_subset$pulmonary_deaths, na.rm = TRUE)
g5_mean_dd <- mean(g5_pred_subset$diabetes_deaths, na.rm = TRUE)
today5 <- max(c_g5$date)
g5_df_pred <- data.frame(date=c(today5),
total_cases=c(g5_mean_tc),
total_cases_per_million=c(g5_mean_tcpm),
total_deaths=c(g5_mean_td),
total_deaths_per_million=c(g5_mean_tdpm),
new_deaths=c(g5_mean_nd),
population=c(g5_mean_p),
pulmonary_deaths=c(g5_mean_pd),
cardiovascular_deaths=c(g5_mean_cd),
diabetes_deaths=c(g5_mean_dd))
# hacemos prediccion
g5_pred_new_cases <- predict(object=lm_c_g5, newdata=g5_df_pred)
# creamos df con la prediccion y fecha actual
g5_pred_df_result <- data.frame(date=g5_df_pred$date,g5_pred_new_cases)
# Leemos las predicciones anteriores...
g5_pred_df_final <- read.csv("C-top10Cluster5Pred.csv")
g5_pred_df_final$date <- as.Date(g5_pred_df_final$date, format="%Y-%m-%d")
g5_pred_df_final <- subset(g5_pred_df_final, select = -c(X))
# creamos un df con las predicciones anteriores + actual
g5_pred_df_final <- rbind(g5_pred_df_final,g5_pred_df_result)
# Export predictions for each cluster
write.csv(g5_pred_df_final, file = "C-top10Cluster5Pred.csv")
# Seleccionamos las categóricas que nos dieron resultados más significativos
lm_c_g1 <- lm(new_cases ~ total_cases + total_cases_per_million + total_deaths +
total_deaths_per_million + total_tests_per_thousand + total_tests + new_deaths +
population + cardiovascular_deaths + pulmonary_deaths + diabetes_deaths + date, c_g1)
summary(lm_c_g1)
# Cogemos los datos del cluster g1, para la fecha más actual del dataframe
# Duda: ¿Está bien coger sólo 1 día o tendríamos que haber cogido más para hacer la predicción?
g1_pred_subset <- subset(c_g1, date == max(c_g1$date))
# Hacemos la media de las variables para tener los datos medios del cluster
g1_mean_tc <- mean(g1_pred_subset$total_cases, na.rm = TRUE)
g1_mean_tcpm <- mean(g1_pred_subset$total_cases_per_million, na.rm = TRUE)
g1_mean_td <- mean(g1_pred_subset$total_deaths,na.rm = TRUE)
g1_mean_tdpm <- mean(g1_pred_subset$total_deaths_per_million, na.rm = TRUE)
g1_mean_ttpt <- mean(g1_pred_subset$total_tests_per_thousand, na.rm = TRUE)
g1_mean_tt <- mean(g1_pred_subset$total_tests, na.rm = TRUE)
g1_mean_nd <- mean(g1_pred_subset$new_deaths, na.rm = TRUE)
g1_mean_p <- mean(g1_pred_subset$population, na.rm = TRUE)
g1_mean_cd <- mean(g1_pred_subset$cardiovascular_deaths, na.rm = TRUE)
g1_mean_pd <- mean(g1_pred_subset$pulmonary_deaths, na.rm = TRUE)
g1_mean_dd <- mean(g1_pred_subset$diabetes_deaths, na.rm = TRUE)
today <- max(c_g1$date)
# mean_tc_c1
g1_df_pred <- data.frame(date=c(today),
total_cases=c(g1_mean_tc),
total_cases_per_million=c(g1_mean_tcpm),
total_deaths=c(g1_mean_td),
total_deaths_per_million=c(g1_mean_tdpm),
total_tests_per_thousand=c(g1_mean_ttpt),
total_tests=c(g1_mean_tt),
new_deaths=c(g1_mean_nd),
population=c(g1_mean_p),
cardiovascular_deaths=c(g1_mean_cd),
pulmonary_deaths=c(g1_mean_pd),
diabetes_deaths=c(g1_mean_dd))
# hacemos prediccion
g1_pred_new_cases <- predict(object=lm_c_g1, newdata=g1_df_pred)
# creamos df con la prediccion y fecha actual
g1_pred_df_result <- data.frame(date=g1_df_pred$date,g1_pred_new_cases)
# Leemos las predicciones anteriores...
g1_pred_df_final <- read.csv("C-top10Cluster1Pred.csv")
g1_pred_df_final$date <- as.Date(g1_pred_df_final$date, format="%Y-%m-%d")
g1_pred_df_final <- subset(g1_pred_df_final, select = -c(X))
# creamos un df con las predicciones anteriores + actual
g1_pred_df_final <- rbind(g1_pred_df_final,g1_pred_df_result)
# Export predictions for each cluster
write.csv(g1_pred_df_final, file = "C-top10Cluster1Pred.csv")
# Leemos las predicciones anteriores...
g5_pred_df_final <- read.csv("C-top10Cluster5Pred.csv")  # S3 !!!! Rebecca
g5_pred_df_final$date <- as.Date(g5_pred_df_final$date, format="%Y-%m-%d")
g5_pred_df_final <- subset(g5_pred_df_final, select = -c(X))
# creamos un df con las predicciones anteriores + actual
g5_pred_df_final <- rbind(g5_pred_df_final,g5_pred_df_result)
# Export predictions for each cluster
write.csv(g5_pred_df_final, file = "C-top10Cluster5Pred.csv")  # S3 !!!! Rebecca
#data <- read.csv("https://mvtec-group2.s3-eu-west-1.amazonaws.com/rawdata/A_covidDaily.csv")
# Add a try catch
data <- read.csv("https://raw.githubusercontent.com/owid/covid-19-data/master/public/data/owid-covid-data.csv")
data <- rename(data, code = iso_code)
head(data)   # mostrar 10 1es files cada colm
names(data)  # mostrar nom columnes
# is R reading data correctly?
# Has dd the correct number of ROWS and COLUMNS?
dim(data)
# TIPO DE OBJETO DATOS
class(data)
#are all columns of expected types?
sapply(data, class)
# ens quedem amb les columnes que tenen menys NA's
apply(
is.na
(data), 2, mean)
# reduir la bd eliminant colm --> https://www.listendata.com/2015/06/r-keep-drop-columns-from-data-frame.html
data <- subset(data, select = c(code, continent, location, date, total_cases, total_cases_per_million, new_cases, reproduction_rate, total_deaths, total_deaths_per_million, new_deaths, hospital_beds_per_thousand, total_tests, total_tests_per_thousand, population, population_density, median_age, gdp_per_capita))
## dates ##
class(data$date)  # --> ha ser data i no caràcter
library(lubridate)
#data$date <- ymd(data$date)
data$date <- as.Date(data$date, format="%Y-%m-%d")
class(data$date)
# x saber quants NA hi ha per colm
apply(is.na(data), 2, sum) # 2 = columnes
ob <- read.csv("obesitat.csv")
sapply(ob, class)
ob <- rename(ob, country = Entity, code = Code, year = Year, obesity = Prevalence.of.obesity..both.sexes....WHO..2019.)
# taking 2016 year values only
ob <- filter(ob, year==2016)
# removing some rows that don't serve
ob <- ob[!(ob$country=="Africa" | ob$country=="Americas" | ob$country=="Eastern Mediterranean" | ob$country=="Europe" | ob$country=="Global" | ob$country=="South-East Asia" | ob$country=="Western Pacific"),]
head(ob)
ob <- subset(ob, select = -c(year))
dataDeaths <- read.csv("mortality_causes.csv")
# renaming columns and rows
dataDeaths <- rename(dataDeaths, location = Country, causes = Causes, numDeathsOther = Both.sexes)
dataDeaths$location [dataDeaths$location == "Cabo Verde"] <- "Cape Verde"
dataDeaths$location [dataDeaths$location == "United States of America"] <- "United States"
dataDeaths$location [dataDeaths$location == "Republic of Moldova"] <- "Moldova"
dataDeaths$location [dataDeaths$location == "Bolivia (Plurinational State of)"] <- "Bolivia"
# removing column year
dataDeaths <- dataDeaths[,-2]
head(dataDeaths)
library(reshape2)
dataDeaths <- dcast(dataDeaths,location~causes)
head(dataDeaths)
#class(dataDeathsOk)
dataDeaths <- rename(dataDeaths, cardiovascular_deaths = "Cardiovascular diseases", pulmonary_deaths = "Chronic obstructive pulmonary disease", diabetes_deaths = "Diabetes mellitus", cancer_deaths = "Malignant neoplasms")
names(dataDeaths)
# top 10 countries
top10Deaths <- dataDeaths %>%
filter(location %in% c("Cape Verde", "South Africa", "Djibouti", "Sao Tome and Principe", "Libya", "Gabon", "Eswatini", "Equatorial Guinea", "Morocco", "Namibia",
"Qatar", "Bahrain", "Kuwait", "Armenia", "Israel", "Oman", "Maldives", "Singapore", "Georgia", "United Arab Emirates",
"Andorra", "San Marino", "Vatican", "Luxembourg", "Montenegro", "Belgium", "Spain", "Czechia", "Moldova", "Switzerland",
"Panama", "Costa Rica", "Dominican Republic", "Bahamas", "Honduras", "Mexico", "Belize", "Canada", "Guatemala",
"Australia", "New Zealand", "Marshall Islands", "Papua New Guinea", "Fiji", "Solomon Islands", "Vanuatu", "Samoa",
"Chile", "Peru", "Argentina", "Colombia", "Bolivia", "Ecuador", "Suriname", "Paraguay", "Guyana","Brazil","United States"))
head(top10Deaths)
top10Deaths <- rename(top10Deaths, country = location)
dataSecurity <- read.csv("healthSecurity.csv")
head(dataSecurity)
dataTemp <- read.csv("temperatura.csv")
dataTemp <- subset(dataTemp, select = -c(X))
dataTemp <- rename(dataTemp, country = Country)
write.csv(dataTemp, file = "B-top10DataTemperature.csv")
# info countries extra - Karina#
library(readxl)    # x poder llegir arxiu, q és xlsx
pp <- read_excel("country-info.xlsx")
head(pp)
sapply(pp, class)
# seleccionar colm ok
pp <- subset(pp, select = c(COUNTRY, Government_Type, Corruption_preception))
# canviar nom colm
pp <- rename(pp, country = COUNTRY, gov = Government_Type, corruption = Corruption_preception)
# obesity + info paisos extra
obExtra <- left_join(ob, pp, by = "country")
head(obExtra)
extra <- left_join(top10Deaths, dataSecurity, by = "country")
#extra <- left_join(extra, dataTemp, by = "country")
extra <- left_join(obExtra, extra, by = "country")
# top 10 countries extra
extra <- extra %>%
filter(country %in% c("Cape Verde", "South Africa", "Djibouti", "Sao Tome and Principe", "Libya", "Gabon", "Eswatini", "Equatorial Guinea", "Morocco", "Namibia",
"Qatar", "Bahrain", "Kuwait", "Armenia", "Israel", "Oman", "Maldives", "Singapore", "Georgia", "United Arab Emirates",
"Andorra", "San Marino", "Vatican", "Luxembourg", "Montenegro", "Belgium", "Spain", "Czechia", "Moldova", "Switzerland",
"Panama", "Costa Rica", "Dominican Republic", "Bahamas", "Honduras", "Mexico", "Belize", "Canada", "Guatemala",
"Australia", "New Zealand", "Marshall Islands", "Papua New Guinea", "Fiji", "Solomon Islands", "Vanuatu", "Samoa",
"Chile", "Peru", "Argentina", "Colombia", "Bolivia", "Ecuador", "Suriname", "Paraguay", "Guyana","Brazil","United States"))
# extra + covid data
dataOk <- left_join(data, extra, by = "code")
dataOk <- subset(dataOk, select = -c(country))
# dataOk = extra + covid
dataOk <- dataOk %>%
filter(location %in% c("Cape Verde", "South Africa", "Djibouti", "Sao Tome and Principe", "Libya", "Gabon", "Eswatini", "Equatorial Guinea", "Morocco", "Namibia",
"Qatar", "Bahrain", "Kuwait", "Armenia", "Israel", "Oman", "Maldives", "Singapore", "Georgia", "United Arab Emirates",
"Andorra", "San Marino", "Vatican", "Luxembourg", "Montenegro", "Belgium", "Spain", "Czechia", "Moldova", "Switzerland",
"Panama", "Costa Rica", "Dominican Republic", "Bahamas", "Honduras", "Mexico", "Belize", "Canada", "Guatemala",
"Australia", "New Zealand", "Marshall Islands", "Papua New Guinea", "Fiji", "Solomon Islands", "Vanuatu", "Samoa",
"Chile", "Peru", "Argentina", "Colombia", "Bolivia", "Ecuador", "Suriname", "Paraguay", "Guyana","Brazil","United States"))
write.csv(dataOk, file = "B-top10Data.csv")
#setwd("~/AMAZON") !!!! Rebecca
top10 <- read.csv("B-top10Data.csv") # S3 !!!! Rebecca
=======
3*3
a=2
b<-2
3->c
knitr::opts_chunk$set(echo = TRUE)
```{r cars}
knitr::opts_chunk$set(echo = TRUE)
```{r cars}
summary(cars)
plot(pressure)
install.packages("tidyverse")
# Cluster g2
c_g2 <- top10 %>%
filter(location %in% c("Panama", "Montenegro", "Armenia", "Oman", "Maldives","Morocco", "Moldova", "Costa Rica", "Cape Verde", "Georgia", "Bahamas", "Bolivia", "Dominican Republic", "Ecuador", "Belize", "Honduras", "Suriname", "Djibouti", "Libya", "Paraguay", "Sao Tome and Principe", "Guatemala", "Eswatini", "Gabon", "Namibia", "Guyana",  "Equatorial Guinea", "New Zealand", "Marshall Islands", "Papua New Guinea","Fiji", "Solomon Islands", "Samoa", "Vanuatu"))
setwd("~/Desktop/MVTEC/Statistical Programming/projecte/MVTEC-Stats-Project1/Rscripts")
install.packages("readr")
install.packages("tidyverse")
library(readr)
library(tidyverse)
top10 <- read.csv("B-top10DataFixCluster.csv")
>>>>>>> b4971d96e719779090732c5618f8b20bdd30de12
top10 <- subset(top10, select = -c(X))
head(top10)   # mostrar 10 1es files cada colm
names(top10)  # mostrar nom colm
library(lubridate)
top10$date <- as.Date(top10$date, format="%Y-%m-%d")
#top10cluster - agrupem per location, code and continent & treiem na's fent la mitjana
top10cluster <- top10 %>%
group_by(code, location, continent) %>%  # si date es posa aquí, apareix cada país per cada dia
summarise(date = first(date),
m_tcpm = mean(total_cases_per_million, na.rm = TRUE),   # si date es posa a summarise, apareix 1 país x 1 dia (agafa el 23 gen20)
total_cases = mean(total_cases, na.rm = TRUE),
new_cases = mean(new_cases, na.rm = TRUE),
reproduction_rate = mean(reproduction_rate, na.rm = TRUE),
total_deaths = mean(total_deaths, na.rm = TRUE),
total_deaths_per_million = mean(total_deaths_per_million, na.rm = TRUE),
new_deaths = mean(new_deaths, na.rm = TRUE),
hospital_beds_per_thousand = mean(hospital_beds_per_thousand, na.rm = TRUE),
total_tests = mean(total_tests, na.rm = TRUE),
total_tests_per_thousand = mean(total_tests_per_thousand, na.rm = TRUE),
population = first(population),
population_density = first(population_density),
median_age = first(median_age),
gdp_per_capita = first(gdp_per_capita),
obesity = first(obesity),
cardiovascular_deaths = mean(cardiovascular_deaths, na.rm = TRUE),
pulmonary_deaths = mean(pulmonary_deaths, na.rm = TRUE),
diabetes_deaths = mean(diabetes_deaths, na.rm = TRUE),
cancer_deaths = mean(cancer_deaths, na.rm = TRUE),
#temp = mean(AverageTemperature, na.rm = TRUE),
corruption = first(corruption),
gov = first(gov),
healthSecurity = first(healthSecurity)) %>%
arrange(desc(m_tcpm))
<<<<<<< HEAD
# Transform na & nan to 0 or "no data"
top10clusterAll$obesity[is.na(top10clusterAll$obesity)] <- 0
top10clusterAll$population_density[is.na(top10clusterAll$population_density)] <- 0
top10clusterAll$median_age[is.na(top10clusterAll$median_age)] <- 0
top10clusterAll$gdp_per_capita[is.na(top10clusterAll$gdp_per_capita)] <- 0
top10clusterAll$corruption[is.na(top10clusterAll$corruption)] <- "no data"
top10clusterAll$gov[is.na(top10clusterAll$gov)] <- "no data"
top10clusterAll$healthSecurity[is.na(top10clusterAll$healthSecurity)] <- "no data"
top10clusterAll$reproduction_rate[is.nan(top10clusterAll$reproduction_rate)] <- 0
top10clusterAll$total_deaths[is.nan(top10clusterAll$total_deaths)] <- 0
top10clusterAll$total_deaths_per_million[is.nan(top10clusterAll$total_deaths_per_million)] <- 0
top10clusterAll$hospital_beds_per_thousand[is.nan(top10clusterAll$hospital_beds_per_thousand)] <- 0
top10clusterAll$total_tests_per_thousand[is.nan(top10clusterAll$total_tests_per_thousand)] <- 0
top10clusterAll$total_tests[is.nan(top10clusterAll$total_tests)] <- 0
top10clusterAll$new_deaths[is.nan(top10clusterAll$new_deaths)] <- 0
top10clusterAll$cardiovascular_deaths[is.nan(top10clusterAll$cardiovascular_deaths)] <- 0
top10clusterAll$pulmonary_deaths[is.nan(top10clusterAll$pulmonary_deaths)] <- 0
top10clusterAll$diabetes_deaths[is.nan(top10clusterAll$diabetes_deaths)] <- 0
top10clusterAll$cancer_deaths[is.nan(top10clusterAll$cancer_deaths)] <- 0
# Comprovem que no hi ha na's
apply(
is.na
(top10clusterAll), 2, mean)
str(top10clusterAll) # x veure tipus dada. x clust: caràcters han ser factors
top10clusterAll$location <- as.factor(top10clusterAll$location)
class(top10clusterAll$location)
top10clusterAll$continent <- as.factor(top10clusterAll$continent)
class(top10clusterAll$continent)
top10clusterAll$code <- as.factor(top10clusterAll$code)
class(top10clusterAll$code)
top10clusterAll$gov <- as.factor(top10clusterAll$gov)
class(top10clusterAll$gov)
top10clusterAll$corruption <- as.factor(top10clusterAll$corruption)
class(top10clusterAll$corruption)
top10clusterAll$healthSecurity <- as.factor(top10clusterAll$healthSecurity)
class(top10clusterAll$healthSecurity)
=======
top10cluster$obesity[is.na(top10cluster$obesity)] <- 0
top10cluster$population_density[is.na(top10cluster$population_density)] <- 0
top10cluster$median_age[is.na(top10cluster$median_age)] <- 0
top10cluster$gdp_per_capita[is.na(top10cluster$gdp_per_capita)] <- 0
top10cluster$corruption[is.na(top10cluster$corruption)] <- "no data"
top10cluster$gov[is.na(top10cluster$gov)] <- "no data"
top10cluster$healthSecurity[is.na(top10cluster$healthSecurity)] <- "no data"
top10cluster$reproduction_rate[is.nan(top10cluster$reproduction_rate)] <- 0
top10cluster$total_deaths[is.nan(top10cluster$total_deaths)] <- 0
top10cluster$total_deaths_per_million[is.nan(top10cluster$total_deaths_per_million)] <- 0
top10cluster$hospital_beds_per_thousand[is.nan(top10cluster$hospital_beds_per_thousand)] <- 0
top10cluster$total_tests_per_thousand[is.nan(top10cluster$total_tests_per_thousand)] <- 0
top10cluster$total_tests[is.nan(top10cluster$total_tests)] <- 0
top10cluster$new_deaths[is.nan(top10cluster$new_deaths)] <- 0
top10cluster$cardiovascular_deaths[is.nan(top10cluster$cardiovascular_deaths)] <- 0
top10cluster$pulmonary_deaths[is.nan(top10cluster$pulmonary_deaths)] <- 0
top10cluster$diabetes_deaths[is.nan(top10cluster$diabetes_deaths)] <- 0
top10cluster$cancer_deaths[is.nan(top10cluster$cancer_deaths)] <- 0
# Comprovem que no hi ha na's
apply(
is.na
(top10cluster), 2, mean)
str(top10cluster) # x veure tipus dada. x clust: caràcters han ser factors
top10cluster$location <- as.factor(top10cluster$location)
class(top10cluster$location)
top10cluster$continent <- as.factor(top10cluster$continent)
class(top10cluster$continent)
top10cluster$code <- as.factor(top10cluster$code)
class(top10cluster$code)
top10cluster$gov <- as.factor(top10cluster$gov)
class(top10cluster$gov)
top10cluster$corruption <- as.factor(top10cluster$corruption)
class(top10cluster$corruption)
top10cluster$healthSecurity <- as.factor(top10cluster$healthSecurity)
class(top10cluster$healthSecurity)
>>>>>>> b4971d96e719779090732c5618f8b20bdd30de12
library(lubridate)
top10cluster$date <- as.Date(top10cluster$date, format="%Y-%m-%d")
class(top10cluster$date)
top10cluster <-top10cluster[-c(13), ]
top10cluster <-top10cluster[-c(15),]
library(cluster)
str(top10cluster)
top10Matrix4 <- daisy(top10cluster[,c(5:23)], metric = "gower", stand=TRUE)
top10dist4 <- top10Matrix4^2
h4 <- hclust(top10dist4, method="ward.D2")
plot(h4, labels = top10cluster$location, hang = -1, cex = 0.3, cex.axis=0.5, cex.lab=0.5)
cluster4 <- cutree(h4, k=4)
table(cluster4)
rect.hclust(h4, k=4, border=2:5)
cluster <- cluster4
# Ajuntem la columna cluster al data frame top10cluster
top10cluster <- cbind(top10cluster, cluster)
top10cluster <- rename(top10cluster, cluster = "...27")
names(top10cluster)
# Cluster g1
c_g1 <- top10 %>%
filter(location %in% c("Qatar", "Bahrain", "Luxembourg", "Kuwait", "United Arab Emirates","Singapore"))
table(c_g1$location)
c_g1_mean <- top10cluster %>%
filter(location %in% c("Qatar", "Bahrain", "Luxembourg", "Kuwait", "United Arab Emirates","Singapore"))
# Cluster g2
c_g2 <- top10 %>%
filter(location %in% c("Panama", "Montenegro", "Armenia", "Oman", "Maldives","Morocco", "Moldova", "Costa Rica", "Cape Verde", "Georgia", "Bahamas", "Bolivia", "Dominican Republic", "Ecuador", "Belize", "Honduras", "Suriname", "Djibouti", "Libya", "Paraguay", "Sao Tome and Principe", "Guatemala", "Eswatini", "Gabon", "Namibia", "Guyana",  "Equatorial Guinea", "New Zealand", "Marshall Islands", "Papua New Guinea","Fiji", "Solomon Islands", "Samoa", "Vanuatu"))
table(c_g2$location)
c_g2_mean <- top10cluster %>%
filter(location %in% c("Panama", "Montenegro", "Armenia", "Oman", "Maldives","Morocco", "Moldova", "Costa Rica", "Cape Verde", "Georgia", "Bahamas", "Bolivia", "Dominican Republic", "Ecuador", "Belize", "Honduras", "Suriname", "Djibouti", "Libya", "Paraguay", "Sao Tome and Principe", "Guatemala", "Eswatini", "Gabon", "Namibia", "Guyana",  "Equatorial Guinea", "New Zealand", "Marshall Islands", "Papua New Guinea","Fiji", "Solomon Islands", "Samoa", "Vanuatu"))
# Cluster g3
c_g3 <- top10 %>%
filter(location %in% c("Chile", "Israel", "Belgium", "Czechia", "Switzerland", "Canada","Australia"))
table(c_g3$location)
c_g3_mean <- top10cluster %>%
filter(location %in% c("Chile", "Israel", "Belgium", "Czechia", "Switzerland", "Canada","Australia"))
# Cluster g4
c_g4 <- top10 %>%
filter(location %in% c("Peru", "Spain", "Argentina", "Colombia", "South Africa", "Mexico"))
table(c_g4$location)
c_g4_mean <- top10cluster %>%
filter(location %in% c("Peru", "Spain", "Argentina", "Colombia", "South Africa", "Mexico"))
# Cluster g5
c_g5 <- top10 %>%
filter(location %in% c("United States", "Brazil"))
table(c_g5$location)
<<<<<<< HEAD
c_g5_mean <- top10clusterAll %>%
filter(location %in% c("United States", "Brazil"))
# Seleccionamos las categóricas que nos dieron resultados más significativos
lm_c_g1 <- lm(new_cases ~ total_cases + total_cases_per_million + total_deaths +
total_deaths_per_million + total_tests_per_thousand + total_tests + new_deaths +
population + cardiovascular_deaths + pulmonary_deaths + diabetes_deaths + date, c_g1)
summary(lm_c_g1)
# Cogemos los datos del cluster g1, para la fecha más actual del dataframe
# Duda: ¿Está bien coger sólo 1 día o tendríamos que haber cogido más para hacer la predicción?
g1_pred_subset <- subset(c_g1, date == max(c_g1$date))
# Hacemos la media de las variables para tener los datos medios del cluster
g1_mean_tc <- mean(g1_pred_subset$total_cases, na.rm = TRUE)
g1_mean_tcpm <- mean(g1_pred_subset$total_cases_per_million, na.rm = TRUE)
g1_mean_td <- mean(g1_pred_subset$total_deaths,na.rm = TRUE)
g1_mean_tdpm <- mean(g1_pred_subset$total_deaths_per_million, na.rm = TRUE)
g1_mean_ttpt <- mean(g1_pred_subset$total_tests_per_thousand, na.rm = TRUE)
g1_mean_tt <- mean(g1_pred_subset$total_tests, na.rm = TRUE)
g1_mean_nd <- mean(g1_pred_subset$new_deaths, na.rm = TRUE)
g1_mean_p <- mean(g1_pred_subset$population, na.rm = TRUE)
g1_mean_cd <- mean(g1_pred_subset$cardiovascular_deaths, na.rm = TRUE)
g1_mean_pd <- mean(g1_pred_subset$pulmonary_deaths, na.rm = TRUE)
g1_mean_dd <- mean(g1_pred_subset$diabetes_deaths, na.rm = TRUE)
today <- max(c_g1$date)
# mean_tc_c1
g1_df_pred <- data.frame(date=c(today),
total_cases=c(g1_mean_tc),
total_cases_per_million=c(g1_mean_tcpm),
total_deaths=c(g1_mean_td),
total_deaths_per_million=c(g1_mean_tdpm),
total_tests_per_thousand=c(g1_mean_ttpt),
total_tests=c(g1_mean_tt),
new_deaths=c(g1_mean_nd),
population=c(g1_mean_p),
cardiovascular_deaths=c(g1_mean_cd),
pulmonary_deaths=c(g1_mean_pd),
diabetes_deaths=c(g1_mean_dd))
# hacemos prediccion
g1_pred_new_cases <- predict(object=lm_c_g1, newdata=g1_df_pred)
# creamos df con la prediccion y fecha actual
g1_pred_df_result <- data.frame(date=g1_df_pred$date,g1_pred_new_cases)
# Leemos las predicciones anteriores...
g1_pred_df_final <- read.csv("C-top10Cluster1Pred.csv")  # S3 !!!! Rebecca
g1_pred_df_final$date <- as.Date(g1_pred_df_final$date, format="%Y-%m-%d")
g1_pred_df_final <- subset(g1_pred_df_final, select = -c(X))
# creamos un df con las predicciones anteriores + actual
g1_pred_df_final <- rbind(g1_pred_df_final,g1_pred_df_result)
# Export predictions for each cluster
write.csv(g1_pred_df_final, file = "C-top10Cluster1Pred.csv")  # S3 !!!! Rebecca
lm_c_g4 <- lm(new_cases ~ total_cases + total_cases_per_million + total_deaths +
total_deaths_per_million + new_deaths +
population + median_age + gdp_per_capita + cardiovascular_deaths + diabetes_deaths + date, c_g4)
summary(lm_c_g4)
# Cogemos los datos del cluster g4, para la fecha más actual del dataframe
# Duda: ¿Está bien coger sólo 1 día o tendríamos que haber cogido más para hacer la predicción?
g4_pred_subset <- subset(c_g4, date == max(c_g4$date))
# Hacemos la media de las variables para tener los datos medios del cluster
# eliminamos total_tests_per_thousand y total_tests de la prediccion porque en este cluster hay demasiados NA's
g4_mean_tc <- mean(g4_pred_subset$total_cases, na.rm = TRUE)
g4_mean_tcpm <- mean(g4_pred_subset$total_cases_per_million, na.rm = TRUE)
g4_mean_td <- mean(g4_pred_subset$total_deaths,na.rm = TRUE)
g4_mean_tdpm <- mean(g4_pred_subset$total_deaths_per_million, na.rm = TRUE)
#g4_mean_ttpt <- mean(g4_pred_subset$total_tests_per_thousand, na.rm = TRUE)
#g4_mean_tt <- mean(g4_pred_subset$total_tests, na.rm = TRUE)
g4_mean_nd <- mean(g4_pred_subset$new_deaths, na.rm = TRUE)
g4_mean_p <- mean(g4_pred_subset$population, na.rm = TRUE)
g4_mean_ma <- mean(g4_pred_subset$median_age, na.rm = TRUE)
g4_mean_gdp <- mean(g4_pred_subset$gdp_per_capita, na.rm = TRUE)
g4_mean_cd <- mean(g4_pred_subset$cardiovascular_deaths, na.rm = TRUE)
g4_mean_dd <- mean(g4_pred_subset$diabetes_deaths, na.rm = TRUE)
today4 <- max(c_g4$date)
g4_df_pred <- data.frame(date=c(today4),
total_cases=c(g4_mean_tc),
total_cases_per_million=c(g4_mean_tcpm),
total_deaths=c(g4_mean_td),
total_deaths_per_million=c(g4_mean_tdpm),
new_deaths=c(g4_mean_nd),
population=c(g4_mean_p),
median_age=c(g4_mean_ma),
gdp_per_capita=c(g4_mean_gdp),
cardiovascular_deaths=c(g4_mean_cd),
diabetes_deaths=c(g4_mean_dd))
# hacemos prediccion
g4_pred_new_cases <- predict(object=lm_c_g4, newdata=g4_df_pred)
# creamos df con la prediccion y fecha actual
g4_pred_df_result <- data.frame(date=g4_df_pred$date,g4_pred_new_cases)
# Leemos las predicciones anteriores...
g4_pred_df_final <- read.csv("C-top10Cluster4Pred.csv")   # S3 !!!! Rebecca
g4_pred_df_final$date <- as.Date(g4_pred_df_final$date, format="%Y-%m-%d")
g4_pred_df_final <- subset(g4_pred_df_final, select = -c(X))
# creamos un df con las predicciones anteriores + actual
g4_pred_df_final <- rbind(g4_pred_df_final,g4_pred_df_result)
# Export predictions for each cluster
write.csv(g4_pred_df_final, file = "C-top10Cluster4Pred.csv")  # S3 !!!! Rebecca
=======
install.packages("PerformanceAnalytics")
install.packages("corrplot")
library(corrplot)
library(PerformanceAnalytics)
# Cluster g2 - Matrix correlation -> variables NO temporales (lo hacemos con la media)
chart.Correlation(c_g2_mean[,c(5:23)], histogram = FALSE, method = "pearson")
# Cluster g3 - Matrix correlation -> variables temporales
chart.Correlation(c_g3[,c(5:11,13,14)], histogram = FALSE, method = "pearson")
c_g3_mean <- top10cluster %>%
filter(location %in% c("Chile", "Israel", "Belgium", "Czechia", "Switzerland", "Canada","Australia"))
# Cluster g3 - Matrix correlation -> variables NO temporales (lo hacemos con la media)
chart.Correlation(c_g3_mean[,c(5:23)], histogram = FALSE, method = "pearson")
# Cluster g4 - Matrix correlation -> variables temporales
chart.Correlation(c_g4[,c(5:11,13,14)], histogram = FALSE, method = "pearson")
# Cluster g4 - Matrix correlation -> variables NO temporales (lo hacemos con la media)
chart.Correlation(c_g4_mean[,c(5:23)], histogram = FALSE, method = "pearson")
library(readr);
library(tidyverse);
library(readr);
library(tidyverse);
data <- read.csv("https://mvtec-group2.s3-eu-west-1.amazonaws.com/rawdata/A_covidDaily.csv")
View(data)
data <- read.csv("A_covidDaily.csv")
data <- read.csv("A-covidDaily.csv")
View(data)
data <- read.csv("https://mvtec-group2.s3-eu-west-1.amazonaws.com/rawdata/A_covidDaily.csv")
data <- rename(data, code = iso_code)
head(data)   # mostrar 10 1es files cada colm
bkt <- 'mvtec-group2' #S3 bucket
df <- read.csv('B-top10Data.csv')
write.csv(dataOK, file="test.csv")
write.csv(df, file="test.csv")
put_object("test.csv", object = "rawdata/test.csv", bucket = bkt, show_progress = TRUE)
library(aws.s3)
put_object("test.csv", object = "rawdata/test.csv", bucket = bkt, show_progress = TRUE)
put_object("test.csv", object = "rawdata/test.csv", bucket = bkt, show_progress = TRUE)
i
bucketlist()
library(aws.s3)
bkt <- 'mvtec-group2' #S3 bucket
library(aws.s3)
df <- read.csv('B-top10Data.csv')
write.csv(df, file.path(tempdir(),"test.csv"))
put_object(
file = file.path(tempdir(),"test.csv"),
object = "rawdata/test.csv",
bucket = "mvtec-group2",
show_progress = TRUE)
put_object(
file = file.path(tempdir(),"test.csv"),
object = "rawdata/test.csv",
bucket = "mvtec-group2",
show_progress = TRUE)
system("/Users/rvpazos/Documents/mvtec/cross-module-assignment/MVTEC-Stats-Project1/dataPipelineR/.Renviron")
put_object(
file = file.path(tempdir(),"test.csv"),
object = "rawdata/test.csv",
bucket = "mvtec-group2",
show_progress = TRUE)
put_object(
file = file.path(tempdir(),"test.csv"),
object = "rawdata/test.csv",
bucket = "mvtec-group2",
region = "eu-west-1"
show_progress = TRUE)
put_object(
file = file.path(tempdir(),"test.csv"),
object = "rawdata/test.csv",
bucket = "mvtec-group2",
region = "eu-west-1",
show_progress = TRUE)
put_object(
file = file.path(tempdir(),"test.csv"),
object = "rawdata/test.csv",
bucket = "mvtec-group2",
region = "eu-west-1",
acl = "public-read",
show_progress = TRUE)
View(df)
?write.csv
write.csv(df, file.path(tempdir(),"test.csv"), row.names = FALSE)
View(df)
df <- read.csv('B-top10Data.csv')
write.csv(df, file.path(tempdir(),"test.csv"), row.names = FALSE)
View(df)
?read.csv
put_object(
file = file.path(tempdir(),"test.csv"),
object = "rawdata/test.csv",
bucket = "mvtec-group2",
region = "eu-west-1",
acl = "public-read",
content-type = "text/csv",
show_progress = TRUE)
put_object(
file = file.path(tempdir(),"test.csv"),
object = "rawdata/test.csv",
bucket = "mvtec-group2",
region = "eu-west-1",
acl = "public-read",
Content-Type = "text/csv",
show_progress = TRUE)
>>>>>>> b4971d96e719779090732c5618f8b20bdd30de12
