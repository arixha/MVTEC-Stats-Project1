---
title: "R Notebook - prepping data for assignment"
output: html_notebook
---
Setting up my R environment

```{r}
library(dplyr)
library(tidyr)
library(readxl)
library(imputeTS)
library(tseries)
```

*Step 1*: Import 3 datasets

```{r}

#Data import
country_info = read_excel("originalData/country-info.xlsx")
originalCovid = read_excel("originalData/owid-covid-data-clean.xlsx")
ghsIndex = read.csv(file = "additionalData/globalSecurityIndex .csv")

head(country_info)
head(originalCovid)
head(ghsIndex)
```

```{r}
#For originalCovid, make sure date column is reading as date.

dtCorrectedCovid = originalCovid %>%
    mutate(date = as.Date(date, format="%Y-%m-%d"))

head(dtCorrectedCovid)

```

*Step 2*: Join the three datasets

```{r}
mergedData = dtCorrectedCovid %>%
    inner_join(country_info, c("location" = "COUNTRY"))  %>%
    inner_join(ghsIndex, c("location" = "Country"))

sapply(mergedData, class)
head(mergedData)

```

*Step 3*: Filter to only selected columns

```{r}
cleanedData = mergedData %>%
  mutate(week = format(date, format="%W")) %>% #Add a new column with the 'week' number
  subset(select = c(iso_code, continent, location, date, total_cases, total_cases_per_million, new_cases_smoothed, total_deaths, new_deaths_smoothed, reproduction_rate, population, population_density, median_age, gdp_per_capita, Government_Type, Corruption_preception, category))

head(cleanedData)
   
```
*Step 4*: Rename

```{r}
renamedData = cleanedData %>%
  rename(region = continent, country = location, tcpm = total_cases_per_million, rRate = reproduction_rate, popDensity = population_density, gdp = gdp_per_capita, govt = Government_Type, corruption = Corruption_preception, healthSecurity = category, casesSmooth = new_cases_smoothed, deathSmooth = new_deaths_smoothed)

head(renamedData)
```

*Step 5*: See how many with missing data
```{r}
apply(is.na(renamedData), 2, sum)##Checking for each column, how many rows are NAs? 
```

*Step 6*: Group to top 40 for globally based on total cases per million, those with more than 50,000 cases and population higher than one million.

```{r}
#filtering dataset
filtered = renamedData %>%
  filter(date == as.Date("2020-12-04"), total_cases >= 10000, population >= 1000000) %>%
  slice_max(order_by = tcpm, n=50)

head(filtered)
#checking countries per region is even
byRegion = filtered %>% 
  group_by(region) %>%
  summarise(countries = n_distinct(country))
print(byRegion)
  
#extracting selected countries based on criteria set above
selectedCountries = unlist(filtered[,3])
print(selectedCountries)
```

*Step 7* Filter renamedData to create a cleanData for next stage: Clustering, using the list created in Step 6
```{r}
finalData = renamedData %>%
  filter(country %in% selectedCountries)
  
head(finalData)
```
*Step 8* Export FinalData

```{r}
write.csv(finalData, file="data_output/rvpazos_preprocessed.csv",
          row.names=TRUE)
```

