---
title: "R Notebook - prepping data for assignment"
author: "Rebecca Pazos"
output:
  html_document:
    df_print: paged
---
Setting up my R environment

```{r}
library(dplyr)
library(tidyr)
library(readxl)
library(knitr)
```

*Step 1*: Import 3 datasets

```{r}

#Data import
country_info = read_excel("originalData/country-info.xlsx")
originalCovid = read_excel("originalData/owid-covid-data-clean.xlsx")
ghsIndex = read.csv(file = "additionalData/globalSecurityIndex .csv")

head(country_info)
head(originalCovid)
head(ghsIndex)
```

```{r}
#For originalCovid, make sure date column is reading as date.

dtCorrectedCovid = originalCovid %>%
    mutate(date = as.Date(date, format="%Y-%m-%d"))

head(dtCorrectedCovid)

```

*Step 2*: Join the three datasets

```{r}
mergedData = dtCorrectedCovid %>%
    inner_join(country_info, c("location" = "COUNTRY"))  %>%
    inner_join(ghsIndex, c("location" = "Country"))

sapply(mergedData, class)
head(mergedData)

```

*Step 3*: Filter to only selected columns

```{r}
cleanedData = mergedData %>%
  mutate(week = format(date, format="%W")) %>% #Add a new column with the 'week' number
  subset(select = c(iso_code, continent, location, date, week, total_cases, total_cases_per_million, new_cases_smoothed, total_deaths, new_deaths_smoothed, reproduction_rate, population, population_density, median_age, gdp_per_capita, Government_Type, Corruption_preception, category))

head(cleanedData)
   
```
*Step 4*: Rename

```{r}
renamedData = cleanedData %>%
  rename(region = continent, country = location, tcpm = total_cases_per_million, rRate = reproduction_rate, popDensity = population_density, gdp = gdp_per_capita, govt = Government_Type, corruption = Corruption_preception, healthSecurity = category, casesSmooth = new_cases_smoothed, deathSmooth = new_deaths_smoothed)

head(renamedData)
```

*Step 5*: See how many with missing data
```{r}
apply(is.na(renamedData), 2, sum)##Checking for each column, how many rows are NAs? 
```

*Step 6*: Here we can change the filters. At the moment, it is set to the top 50 globally based on total cases per million, those with more than 50,000 cases and population higher than one million.

```{r}
#filtering dataset
filtered = renamedData %>%
  filter(date == as.Date("2020-12-04"), total_cases >= 10000, population >= 1000000) %>%
  slice_max(order_by = tcpm, n=50) %>%
  group_by(week)

head(filtered)
#checking countries per region is even
byRegion = filtered %>% 
  group_by(region) %>%
  summarise(countries = n_distinct(country))
print(byRegion)
  
#extracting selected countries based on criteria set above
selectedCountries = unlist(filtered[,3])
print(selectedCountries)
```

*Step 7* Filter renamedData to create a cleanData for next stage: Clustering, using the list created in Step 6
```{r}
finalData = renamedData %>%
  #Based on countries filtered in the above chunk.
  filter(country %in% selectedCountries) %>% 
  #Adding year as a field as the groupings will need to be grouped by Year > Week, not just Week.
  mutate(year = format(date, "%Y")) %>%
  group_by(year, week, region, country) %>%
  #filter(region == "Asia", date >= "2020-12-01") %>%
  summarise(iso_code = first(iso_code),
            date = min(date),
            totalCases = max(total_cases),
            tcpm = max(tcpm), 
            casesSmooth = mean(casesSmooth), 
            totalDeaths = max(total_deaths), 
            deathSmooth = mean(deathSmooth), 
            population = first(population), 
            popDensity = first(popDensity), 
            medianAge = first(median_age), 
            gdp = first(gdp),
            govt = first(govt),
            corruption = first(corruption),
            healthSecurity = first(healthSecurity)
            )

head(finalData)
```

## My Codebook

Column Name     | Type           | Description
--------------- | -------------- | -------------------
year            | grouping       |
week            | grouping       |
region          | grouping       |
country         | grouping       |
iso_code        | Identifier     |
totalCases      | Main numeric   | Cumulative cases for that country on that date
casesSmooth     | Main numeric   | Average weekly new cases smoothed
tcpm            | Main numeric   | Cumulative total cases per million on that date
totalDeaths     | Main numeric   | Cumulative deaths for that country on that date
deathSmooth     | Main numeric   | Average weekly new deaths smoothed
population      | Additional num | Current population
popDensity      | Additional num | Density of the population with regards to land space
medianAge       | Additional num | Age (older or younger on average?)
gdp             | Additional num | $
govt            | Qualitative    | Types of government
corruption      | Qualitative    | Highly corrupt, Less corrupt
healthSecurity  | Qualitative    | Most prepared, More prepared, Least prepared, 

```{r}
names(finalData)

unique(finalData$govt)

unique(finalData$corruption)

unique(finalData$healthSecurity)
```

*Step 8* Export FinalData
```{r}
write.csv(finalData, file="data_output/rvpazos_preprocessed.csv",
          row.names=FALSE)
```

